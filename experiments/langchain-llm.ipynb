{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By providing examples of extraction, get LLM to follow and extract info in JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\\experiments\n",
      "Running experiment20241015100115\n",
      "Processing chunk0.txt\n",
      "Processing chunk1.txt\n",
      "Processing chunk10.txt\n",
      "Processing chunk11.txt\n",
      "Processing chunk12.txt\n",
      "Processing chunk13.txt\n",
      "Processing chunk14.txt\n",
      "Processing chunk15.txt\n",
      "Processing chunk16.txt\n",
      "Processing chunk17.txt\n",
      "Processing chunk18.txt\n",
      "Processing chunk2.txt\n",
      "Processing chunk3.txt\n",
      "Processing chunk4.txt\n",
      "Processing chunk5.txt\n",
      "Processing chunk6.txt\n",
      "Processing chunk7.txt\n",
      "Processing chunk8.txt\n",
      "Processing chunk9.txt\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from src import *\n",
    "%cd experiments/\n",
    "\n",
    "def extract_code_from_url(url: str):\n",
    "    last_question_mark = url.rfind('?')\n",
    "    code = url[last_question_mark - 32:last_question_mark]\n",
    "    return code\n",
    "\n",
    "def pipeline(filename: str, pageID: str):\n",
    "    \"\"\"Runs full pipeline\"\"\"\n",
    "    docIngest(filename).run()\n",
    "    mdCombine(filename).run()\n",
    "    getChunks(filename).run()\n",
    "    Extractor(filename).run()\n",
    "    Notion(filename, pageID).run()\n",
    "\n",
    "pageURL = \"https://zain273work.notion.site/Test3-11fa89672d99805fb667f5bfc1d9f563?pvs=4\"\n",
    "pageID = extract_code_from_url(pageURL)\n",
    "# print(pageID)\n",
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format it as a string\n",
    "formatted_datetime: str = current_datetime.strftime(\"%Y%m%d%H%M%S\")\n",
    "name: str = \"experiment\" + formatted_datetime\n",
    "print(f\"Running {name}\")\n",
    "pipeline(name, pageID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip installs (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "from src import *\n",
    "%cd experiments/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_from_url(url: str):\n",
    "    last_question_mark = url.rfind('?')\n",
    "    code = url[last_question_mark - 32:last_question_mark]\n",
    "    return code\n",
    "\n",
    "def pipeline(filename: str, pageID: str):\n",
    "    \"\"\"Runs full pipeline\"\"\"\n",
    "    docIngest(filename).run()\n",
    "    mdCombine(filename).run()\n",
    "    getChunks(filename).run()\n",
    "    Extractor(filename).run()\n",
    "    # Squasher(filename).run()\n",
    "    Notion(filename, pageID).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageURL = \"https://zain273work.notion.site/Test3-11fa89672d99805fb667f5bfc1d9f563?pvs=4\"\n",
    "pageID = extract_code_from_url(pageURL)\n",
    "# print(pageID)\n",
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format it as a string\n",
    "formatted_datetime: str = current_datetime.strftime(\"%Y%m%d%H%M%S\")\n",
    "name: str = \"experiment\" + formatted_datetime\n",
    "print(f\"Running {name}\")\n",
    "pipeline(name, pageID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageURL = \"https://zain273work.notion.site/newTest-11fa89672d9980f2b846eb8e98c1c3e4?pvs=4\"\n",
    "pageID = extract_code_from_url(pageURL)\n",
    "name = \"experiment20241014200958\"\n",
    "Notion(name, pageID).run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
