{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By providing examples of extraction, get LLM to follow and extract info in JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip installs (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: langchain_huggingface in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 3)) (0.1.0)\n",
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 4)) (0.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 6)) (3.9.1)\n",
      "Requirement already satisfied: notion-client in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 8)) (0.2.2)\n",
      "Requirement already satisfied: openai in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 9)) (1.51.0)\n",
      "Requirement already satisfied: unstructured[md] in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 5)) (0.15.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (3.10.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (0.3.9)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (0.1.130)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain->-r ../requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain_community->-r ../requirements.txt (line 2)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain_community->-r ../requirements.txt (line 2)) (2.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain_huggingface->-r ../requirements.txt (line 3)) (0.25.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain_huggingface->-r ../requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain_huggingface->-r ../requirements.txt (line 3)) (0.20.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain_huggingface->-r ../requirements.txt (line 3)) (4.45.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (5.3.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (4.12.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (2.13.2)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (3.10.0)\n",
      "Requirement already satisfied: backoff in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (0.25.9)\n",
      "Requirement already satisfied: wrapt in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (6.0.0)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (0.0.1)\n",
      "Requirement already satisfied: markdown in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured[md]->-r ../requirements.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from nltk->-r ../requirements.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from nltk->-r ../requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from nltk->-r ../requirements.txt (line 6)) (2024.9.11)\n",
      "Requirement already satisfied: httpx>=0.15.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from notion-client->-r ../requirements.txt (line 7)) (0.27.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain-openai->-r ../requirements.txt (line 8)) (0.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from openai->-r ../requirements.txt (line 9)) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from openai->-r ../requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from openai->-r ../requirements.txt (line 9)) (0.6.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from openai->-r ../requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 1)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 1)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ../requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->-r ../requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r ../requirements.txt (line 2)) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->-r ../requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from httpx>=0.15.0->notion-client->-r ../requirements.txt (line 7)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from httpx>=0.15.0->notion-client->-r ../requirements.txt (line 7)) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.15.0->notion-client->-r ../requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface->-r ../requirements.txt (line 3)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface->-r ../requirements.txt (line 3)) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface->-r ../requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain->-r ../requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r ../requirements.txt (line 1)) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r ../requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r ../requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r ../requirements.txt (line 1)) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community->-r ../requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r ../requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r ../requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (10.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r ../requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from tqdm->unstructured[md]->-r ../requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface->-r ../requirements.txt (line 3)) (0.4.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from beautifulsoup4->unstructured[md]->-r ../requirements.txt (line 5)) (2.6)\n",
      "Requirement already satisfied: six in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from langdetect->unstructured[md]->-r ../requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: olefile in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from python-oxmsg->unstructured[md]->-r ../requirements.txt (line 5)) (0.47)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (43.0.1)\n",
      "Requirement already satisfied: deepdiff>=6.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (8.0.1)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (1.17.1)\n",
      "Requirement already satisfied: orderly-set==5.2.2 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from deepdiff>=6.0->unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (5.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain->-r ../requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (75.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured[md]->-r ../requirements.txt (line 5)) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zain\\documents\\github\\university\\.venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface->-r ../requirements.txt (line 3)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\\experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\Documents\\Github\\University\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from src import *\n",
    "%cd experiments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"OpenAIApp\"\n",
    "encoding: str = \"utf-32\"\n",
    "class Extractor:\n",
    "    \"\"\"Given example text and extraction, query all chunks of text and collect as JSON. Store in experiments folder\"\"\"\n",
    "    def __init__(self, folder: str):\n",
    "        self.folder = folder\n",
    "    def run(self):\n",
    "        ex: list = self._load_text()\n",
    "        sys: str = self._makeQuery(ex)\n",
    "        num: int = self._getLenChunks()\n",
    "        for i in range(num):\n",
    "            text: str = self._readChunk(i)\n",
    "            # print(text)\n",
    "            response: dict = self._queryLang(sys, text)\n",
    "            self._storeText(response, f\"chunk{i}.txt\")\n",
    "        return text\n",
    "    def _load_text(self) -> list:\n",
    "        \"\"\"Return both example text and example extracted data from it\"\"\"\n",
    "        with open(f\"experiments/{self.folder}/examples/sample_text.txt\", \"r\", encoding = \"ascii\") as file:\n",
    "            example = file.read()\n",
    "            example = unicodedata.normalize('NFC', example)\n",
    "        with open(f\"experiments/{self.folder}/examples/extracted_text.txt\", \"r\", encoding = \"ascii\") as file:\n",
    "            extract = file.read()\n",
    "            extract = unicodedata.normalize('NFC', extract)\n",
    "        return [example, extract]\n",
    "    def _makeQuery(self, list) -> str:\n",
    "        \"\"\"Use list of 2 texts to form system message\"\"\"\n",
    "        content = f\"\"\"\n",
    "Here is an example of some text in which definitions, lemmas, theorems, propositions and corollaries are extracted:\n",
    "\n",
    "{list[0]}\n",
    "\n",
    "And here is the extracted result in json format:\n",
    "\n",
    "{list[1]}\n",
    "\n",
    "You will use the examples given above to perform the same task on the text provided in the user message.\n",
    "\"\"\"\n",
    "        return content\n",
    "    def _getLenChunks(self) -> int:\n",
    "        \"\"\"Return how many times to read chunks\"\"\"\n",
    "        return len(os.listdir(f\"experiments/{self.folder}/chunks/\"))\n",
    "    def _readChunk(self, chunk: int) -> str:\n",
    "        \"\"\"Read in chunk of text\"\"\"\n",
    "        with open(f\"experiments/{self.folder}/chunks/chunk{chunk}.txt\", \"r\", encoding = \"ascii\") as file:\n",
    "            content = file.read()\n",
    "            content = unicodedata.normalize('NFC', content)\n",
    "            return content\n",
    "    def _queryLang(self, sys: str, user: str) -> dict:\n",
    "        \"\"\"Query Langchain and return json of response\"\"\"\n",
    "        # print(sys)\n",
    "        # print(type(user))\n",
    "        llm = ChatOpenAI(model = \"gpt-4o-mini\")\n",
    "        md: str = rf\"\"\"{sys}\"\"\"\n",
    "        md = json.dumps(md.replace(\"{\", \"{{\").replace(\"}\", \"}}\"), indent = 4)\n",
    "        usermd: str = rf\"\"\"{user}\"\"\"\n",
    "        usermd = json.dumps(usermd.replace(\"{\", \"{{\").replace(\"}\", \"}}\"), indent = 4)\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", md),\n",
    "                (\"user\", \"{input}\")\n",
    "            ]\n",
    "        )\n",
    "        chain = prompt|llm # combines both\n",
    "        response = chain.invoke({\"input\": usermd})\n",
    "        return response.content\n",
    "    def _storeText(self, text: str, filename: str) -> None:\n",
    "        \"\"\"Temporarily store as text\"\"\"\n",
    "        os.makedirs(f\"experiments/{self.folder}/output/\", exist_ok = True)\n",
    "        with open(f\"experiments/{self.folder}/output/{filename}\", \"w\") as file:\n",
    "            file.write(text)\n",
    "    def _storeQuery(self, dict, filename:str) -> None:\n",
    "        \"\"\"Store langchain response as .json\"\"\"\n",
    "        os.makedirs(f\"experiments/{self.folder}/output/\", exist_ok = True)\n",
    "        with open(f\"experiments/{self.folder}/output/{filename}\", \"w\") as file:\n",
    "            json.dump(dict, file, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(filename: str):\n",
    "    \"\"\"Runs full pipeline\"\"\"\n",
    "    docIngest(filename).run()\n",
    "    mdCombine(filename).run()\n",
    "    getChunks(filename).run()\n",
    "    Extractor(filename).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder found in experiments/experiment20241007164528\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xef in position 1281: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m formatted_datetime\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFolder found in experiments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      4\u001b[0m mdCombine(filename)\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m      5\u001b[0m getChunks(filename)\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m, in \u001b[0;36mExtractor.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     ex: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     sys: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_makeQuery(ex)\n\u001b[0;32m     22\u001b[0m     num: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getLenChunks()\n",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m, in \u001b[0;36mExtractor._load_text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return both example text and example extracted data from it\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/examples/sample_text.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 32\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     example \u001b[38;5;241m=\u001b[39m unicodedata\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNFC\u001b[39m\u001b[38;5;124m'\u001b[39m, example)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/examples/extracted_text.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\ascii.py:26\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascii_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xef in position 1281: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format it as a string\n",
    "formatted_datetime: str = current_datetime.strftime(\"%Y%m%d%H%M%S\")\n",
    "name: str = \"experiment\" + formatted_datetime\n",
    "print(f\"Folder found in experiments/{name}\")\n",
    "pipeline(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squasher to combine all output chunks into 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
